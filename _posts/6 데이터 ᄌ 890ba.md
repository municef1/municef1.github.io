# 6. 데이터 정리와 확률

## 1차원 데이터

- 시험 점수
    - [45, 26, 57, 67, 40, 30, ....] →획득된 샘플(표본) 샘플은 숫자 하나로  구성

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

## 중심의 지표 : 평균

- 평균 mean
    - 데이터를 모두 더한 후 개수로 나눈 대푯값
    - 가장 많이 사용
    - 이상치에 민감
    
    ![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled.png)
    
    ```python
    X = np.array([45, 26, 57, 67, 40, 30, 55, 60, 95, 500])
    
    # 공식대로 구하기
    print(X.sum()/len(X))
    
    # numpy 기능으로 바로 구하기
    print(X.mean())
    ```
    

이상치에 영향을 많이 받음

```python
# 이상치에 영향을 많이 받음
print(X[:-1].mean())
```

## 중심의 지표 : 중앙값

- 중앙값 median
    - 데이터를 크기 순서로 나열한 후 가장 가운데에 있는 값
    
    ![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%201.png)
    
    ```python
    # 이상치에 영향 별로 없음
    np.median(X)
    ```
    
    ```python
    # 크기 순을 정렬해서 가운데 있는 값
    # 데이터 개수가 짝수면 가운데 두값의 평균
    X.sort()
    X
    ```
    

## 퍼짐의 지표 : 분산과 표준편차

- 분산 variance
    - 편균으로부터 퍼짐의 정도를 숫자로 표현
    
    ![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%202.png)
    

```markdown
score1과 score2는 평균이 똑같음
```

```python
np.random.seed(0)
scores1 = np.random.randint(30, 100, 10)
print(scores1)
print(scores1.mean())
```

```python
scores2 = np.random.randint(50, 90, 10)
print(scores2)
print(scores2.mean())
```

각 데이터에서 평균과의 차이를 구하고 이를 막대그래프로 표현

```python
deviations1 = scores1 - scores1.mean()
deviations1
```

```python
deviations2 = scores2 - scores2.mean()
deviations2
```

```python
fig, ax = plt.subplots(figsize=(10,5), nrows=1, ncols=2, sharey=True)

ax[0].bar(np.arange(10), deviations1, color='C1', edgecolor='k')
ax[0].set_title('scores 1 deviations')
ax[1].bar(np.arange(10), deviations2, color='C2', edgecolor='k')
ax[1].set_title('scores 2 deviations')
plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%203.png)

이 평균과의 차잇값들을 평균해보면 0이됨

```python
print(deviations1.sum() / len(deviations1))
print(deviations2.sum() / len(deviations2))
```

그래서 제곱하여 평균을 냄

```python
# 편차 제곱의 평균[+]
print((deviations1**2).mean())
print((deviations2**2).mean())

# numpy 기능으로 분산 바로 구하기 [+]
print(scores1.var())
print(scores2.var())
```

분산은 평균과의 편차값을 한변으로 하는 정사각형들의 평균 넓이

```python
from matplotlib.patches import Rectangle

fig = plt.figure(dpi=100)
ax = plt.axes()

#          0:-   1:+
colors = ['C1', 'C2']

covs = [ Rectangle( (0,0), x, x, edgecolor='k', 
                   facecolor=colors[1], alpha=0.3) 
            for x in deviations2 ]

for cov in covs:
    ax.add_patch(cov)
    
ax.plot(deviations2, np.zeros_like(deviations2), 'o', color='k')
ax.axhline(y=0, color='k')
ax.axvline(x=0, color='k')
ax.axis('equal')
plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%204.png)

### 표준편차

분산이 제곱되어 구해진 값이므로 제곱근을 구해서 원래 데이터와 비슷한 지표로 만든 값

```python
# # 편차 제곱 평균의 양의 제곱근
print(np.sqrt((deviations1**2).mean()))
print(np.sqrt((deviations2**2).mean()))

# numpy 기능으로 표준편차 바로 구하기 [+]
print(scores1.std())
print(scores2.std())
```

## 분산의 그림 표현

- 분산 variance
    - 평균으로부터 퍼짐의 정도를 한변으로 하는 사각형의 평균 넓이

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%205.png)

## 히스토그램

데이터를 계급으로 나눠 계급에 해당하는 빈도수(도수)를 막대그래프로 그린 그래프

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%206.png)

```python
np.random.seed(0)
scores = np.abs((np.random.randn(500)*13)-65).astype(int)
scores[scores>=100] = 100
```

```python
# 히스토그램[+]
hist, bins = np.histogram(scores, bins=10, range=(0,100))
hist
```

```python
fig = plt.figure()
ax = plt.axes()

ax.hist(scores, bins=10, range=(0,100), color='C1', edgecolor='k')
ax.set_xlabel('scores')
ax.set_ylabel('# of students per 10 point interval')
ax.set_title('bins=10')
plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%207.png)

이 구간을 더 촘촘히 해서 그리면

```python
fig = plt.figure()
ax = plt.axes()

ax.hist(scores, bins=20, range=(0,100), color='C1', edgecolor='k')
ax.set_title('bins=20')
ax.set_xlabel('scores')
ax.set_ylabel('# of students per 5 point interval')
plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%208.png)

## 상자그림 Box Plot

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%209.png)

```python
D = np.array([1,2,3,4,5,6,7,8,9,10])

# 이 데이터는 이상치 존재
# D = np.array([2,3,4,5,6,7,8,9,10,18,20])
```

- 전체 데이터에서 25%, 50%, 75%에 위치하는 값을 Q1, Q2, Q3으로 구함
- 이산 데이터를 줄세우고 25% 위치에 해당하는 값을 구할 때 깔끔하게 정수로 떨어지지 않게 되므로 `interpolation`이란 옵션으로 적당한 값을 선정

```python
Q1 = np.percentile(D, 25, interpolation='nearest')
Q2 = np.percentile(D, 50)
Q3 = np.percentile(D, 75, interpolation='nearest')

print(f"Q1={Q1}, Q2={Q2}, Q3={Q3}")
```

```python
# Q3과 Q1의 차이
IQR = Q3 - Q1
IQR
```

- 식 Q3 + 1.5*IQR 로 가상의 상위 울타리upper fence를 계산하고 그 펜스를 넘어가지 않는 데이터의 최대값을 찾음

```python
upper_fence = Q3 + 1.5*IQR
print(upper_fence)

upper_whisker = np.max(D[D<upper_fence])
print(upper_whisker)
```

- Q1 - 1.5*IQR로 가상의 하위 울타리lower fence를 계산하고 그 펜스를 넘어가지 않는 데이터의 최소값을 찾음

```python
lower_fence = Q1 - 1.5*IQR
print(lower_fence) 

upper_whisker = np.min(D[D>lower_fence])
print(upper_whisker)
```

- matplotlib에서 상자그림을 그림

```python
fig = plt.figure(dpi=100)
ax = plt.axes()

ret = ax.boxplot(D)

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2010.png)

- 그려진 상자그림에서 계산된 값들이 미리 계산한 값들과 일치하는가?

```python
# 위 그림에서 whisker, box의 실제 변이 그려진 좌표를 조사
print("upper whisker", ret['caps'][1].get_xydata()[0,1])
print("Q3", ret['boxes'][0].get_xydata()[2,1])
print("Q2", ret['medians'][0].get_xydata()[0,1])
print("Q1", ret['boxes'][0].get_xydata()[0,1])
print("lower whisker", ret['caps'][0].get_xydata()[0,1])
```

## 2차원 데이터

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2011.png)

```python
# 키
H = np.array([170, 155, 175, 182, 171, 188, 165, 167, 175, 183])
# 몸무게
W = np.array([ 65,  59,  68,  78,  62,  85,  63,  58,  70,  98])

# 신체 정보
X = np.array([H, W])
X
```

- 다차원 데이터의 행렬은 항상 (N, D)

```python
X = X.T
X
```

- 평균 두 개, 분산 두 개

```python
fig = plt.figure(dpi=100)
ax = plt.axes()

ax.plot(X[:,0], X[:,1], 'o', color='k')

# 두 데이터의 평균선 그림
ax.axhline(y=X[:,1].mean(), color='k')
ax.axvline(x=X[:,0].mean(), color='k')

ax.set_xlabel('Height')
ax.set_ylabel('Weight')

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2012.png)

- 앞서 알아본 통계값인 평균, 분산은 각 데이터마다 계산 가능

```python
print("키 평균: ", X[:,0].mean())
print("몸무게 평균: ", X[:,1].mean())

print("키 분산: ", X[:,0].var())
print("몸무게 분산: ", X[:,1].var())
```

## 평균과 분산

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2013.png)

## 공분산 covariance

- 두 평균으로부터 퍼짐의 정도를 한변으로 하는 사각형의 평균 넓이
- 양수 : 두 데이터는 양의 직선관계, X 증가 → Y 증가, X 감소, → Y 감소
- 음수 : 두 데이터는 음의 직선관계, X 증가 → Y 감소, X 감소, → Y 증가
- 거의 0 : 직선의 관계가 없음
- 공분산이 크면 직선의 관계가 더 강한가?

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2014.png)

- 두 데이터 사이의 관계를 나타내는 분산값을 계산
- 공분산의 의미는 두 데이터의 평균값 두개로 계산되는 각각의 편차를 가로변, 세로변으로 하는 직사각형의 평균 넓이
- 여기서는 음의 평균도 존재
- 아래 그림에서 2사분면, 4사분면에 있는 데이터들이 음의 면적에 해당

```python
# 공분산의 그림 표현
# :                +------------------+
# :                |                  |
# :              height               |
# :                |                  |
# :               (xy)---- width -----+
# (xy, w, h)
from matplotlib.patches import Rectangle

fig = plt.figure(dpi=100)
ax = plt.axes()

X_bar = X.mean(axis=0)
X_tilde = X - X_bar

#          0:-   1:+
colors = ['C1', 'C2']

covs = [ Rectangle( (0,0), x[0], x[1], edgecolor='k', 
                   facecolor=colors[((x[0]*x[1])>0).astype(int)], alpha=0.3) 
            for x in X_tilde ]

for cov in covs:
    ax.add_patch(cov)
ax.plot(X_tilde[:,0], X_tilde[:,1], 'o', color='k')
ax.axhline(y=0, color='k')
ax.axvline(x=0, color='k')
ax.set_xlabel('Height')
ax.set_ylabel('Weight')

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2015.png)

```python
# 공분산 직접 계산
np.sum(X_tilde[:,0] * X_tilde[:,1]) / (X_tilde.shape[0]-1)
```

```python
# 공분산
np.cov(X[:,0], X[:,1])
```

## 상관계수 correlation coefficient

- 두 변수의 단위에 상관없이 상관성을 나타내는 지표
- 1에 가까우면 : 두 데이터는 양의 직선관계, X 증가 → Y 증가, X 감소, → Y 감소
- -1에 가까우면 : 두 데이터는 음의 직선관계, X 증가 → Y 감소, X 감소, → Y 증가
- 거의 0 : 직선의 관계가 없음

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2016.png)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2017.png)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2018.png)

## 순열

- 줄 세기
    - a, b, c, d에서 두 개를 골라 줄 세우기
    - (a, b), (a, c), (a, d)
    - (b, a), (b, c), (b, d)
    - (c, a), (c, b), (c, d)
    - (d, a), (d, b), (d, c)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2019.png)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2020.png)

```python
# 위 데이터의 상관계수
np.corrcoef(X.T)
```

```python
# 직선의 상관성이 없는 데이터

x = np.random.uniform(-1, 1, 200)
X_uncorr = np.array( [x, x**2 + np.random.uniform(-0.2, 0.2, 200)]).T

fig = plt.figure()
ax = plt.axes()

ax.plot(X_uncorr[:,0], X_uncorr[:,1], '.')
ax.set_xlabel('x')
ax.set_ylabel('y')

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2021.png)

```python
print(np.corrcoef(X_uncorr.T))
```

## 순열

- ABCDEFG의 순열 중 AB 문자열이 포함된 것은 모두 몇개?

ABCDEFG

문자 하나로 보면 여섯 개의 문자를 배열하는 것으로 6!

```python
import itertools
```

```python
list(itertools.permutations('ABCD', 2))
```

```python
# ABCDEFG -> XCDEFG
len(list(itertools.permutations('XCDEFG', 6)))
```

## 조합

- 선택하기
    - a, b, c, d에서 두 개를 선택하기
    - **(a, b), (a, c), (a, d)**
    - (b, a), **(b, c), (b, d)**
    - (c, a), (c, b), **(c, d)**
    - (d, a), (d, b), (d, c)
    - 굵은 글씨만 살아남!
    - 순열에서 같은 요소가 있는 선택들이 하나로 줄어버림
    - 2!개가 한개로!
        
        ![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2022.png)
        
    
- 남학생 5명, 여학생 7명이 지원한 선발에서 남학생 3명, 여학생 3명 뽑는 방법의 수

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2023.png)

```python
list(itertools.combinations('ABCD', 2))
```

```python
list(
    itertools.product(
        itertools.combinations('12345', 3),
        itertools.combinations('1234567', 3)
    )
)
```

## 확률의 정의

- 수학적 확률
    - 어떤 시행에서 사건 A가 일어날 가능성을 수로 나타낸 것 : P(A)
    - 표본공간 Ω에서 사건 A가 일어날 수학적 확률
        - 표본공간 Ω인 어떤 시행에서 각 결과가 일어날 가능성이 모두 같은 정도로 기대될 때
        - P(A) = n(A) / n(Ω)
        
- 통계적 확률
    - 일어날 가능성이 같은 정도로 기대될 수 없을 때
    - 같은 시행을 n번 반복할 때 사건 A가 일어난 횟수를 r`ₙ`
    - 시행횟수 n 이 한없이 커짐에 따라 r`ₙ` / n 이 일정한 값 P에 가까워지면
    - P는 사건 A의 통계적 확률
    

## 확률은 면적

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2024.png)

## 조건부 확률

- 두 사건 A, B에 대해
- 결합확률 Joint Probability : 두 사건이 동시에 일어날 확률 P(A,B)
- 조건부확률 Conditional Probability : 사건 A가 일어났을 때 사건 B가 일어날 
확률 P(B l A)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2025.png)

- P ( 남학생, 중국어 ) = 45 / 100
- P ( 남학생 l 중국어 ) = 45 / 70

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2026.png)

- **노란색 테두리로 쳐서 범위를 줄였을 때의 확률로 생각하면 됨!!!!!**

45/100

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2027.png)

45 / 70

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2028.png)

## 확률변수 : 이산 확률 변수

- 표본공간의 샘플에 숫자를 할당하는 함수
- 이산 확률 변수
    
    ![스크린샷 2022-04-13 오후 1.52.47.png](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-04-13_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_1.52.47.png)
    

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2029.png)

## 확률 질량함수

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2030.png)

## 기댓값 Expected Value

- 평균
    
    ![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2031.png)
    

## 확률변수의 기댓값

- 평균
    - 행운권 한 장 당 평균 상금 : 총 상금 / 행운권 수

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2032.png)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2033.png)

## 확률변수의 기댓값, 분산, 표준편차

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2034.png)

## 이산확률분포 : 베르누이 분포

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2035.png)

## 이산확률분포 : 멀티누이 분포

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2036.png)

파이썬으로 적으면 빨간 글씨처럼 됨!

- 강사 메모) 
- 멀티누이 분포, 카테고리얼 분포라고도 부르고, 멀티노미얼이라고도 하는데 이건 조금 다른거라 조심해야함!
- 개, 고양이 분류면 베르누이
- 손글씨 분류면 멀티누이

## 확률벡터

- 다변량 확률변수 : 확률변수 여러 개 모임, 숫자의 모임 → 벡터

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2037.png)

세로벡터가 데이터벡터가 되는게 맞겠다..

## 결합확률분포 joint probability distribution

- 확률변수 X, Y를 동시에 고려한 확률분포
- 확률질량함수는 이변수 스칼라 함수이며 0이상의 값을 함숫값으로 가지며 모두 더해서 1이 됨

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2038.png)

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2039.png)

위의 f_XY(x,y) 함수는 
다변수 스칼라 함수 중에서 이변수 스칼라 함수인거임

Y가 8일 확률 > 0.5 (파란색)

X가 5일 확률 > 0.3 (빨간색)

이런식으로 보게 됨
이걸 마지날레이션?이라고 함. 주변화 시킨다고 하는데 노란색 테두리 주변에 놓는다고 주변화라고 함..

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2040.png)

빨간 테두리 안에서 생각하면. Y에 대한 확률을 보는것인데

P(y l x = 5),  y =8일 확률은 0, 9일 확률은 1이 되는거라고 보면 됨!

P(x l y = 8), x = 5일 확률은 0, 6일 확률은 0.4/0.5로 0.8, 7일 확률은 0.1/0.5로 0.2가 됨!

## 파이썬에서의 분포 연습

### 베르누이 분포

- scipy의 기능을 이용해 모수 `mu`를 지정하여 확률변수 정의

```python
mu = 0.25

# 확률변수 정의
bern_rv = bernoulli(mu)

# 확률질량함수
print(f"P(X=1)={bern_rv.pmf(1)}, \
        P(X=0)={bern_rv.pmf(0)}")

fig = plt.figure(figsize=(6,5))
ax = plt.axes()

xticks = [0, 1]

ax.bar([0, 1], [bern_rv.pmf(0), bern_rv.pmf(1)], color='0.7', edgecolor='k')
ax.set_xticks(xticks)
ax.set_xlabel(r"$X$")
ax.set_ylabel("Probability")
ax.set_title(r"Bernoulli Distribution for $\mu$=0.25")

ax.tick_params(axis='x', labelsize="small")
ax.tick_params(axis='y', labelsize="small")

# axes의 right, top 축 감추기
ax.spines["right"].set_visible(False)
ax.spines["top"].set_visible(False)

plt.show()
```

P(X=1)=0.25, P(X=0)=0.75

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2041.png)

### 베르누이 분포 시뮬레이션

- 정의된 확률변수로 부터 데이터를 샘플링하여 이론적인 분포와 비슷하게 샘플들이 분포하는지 확인

```python
# 랜덤 샘플링
samples = bern_rv.rvs(size=100)

fig = plt.figure(figsize=(6,5))
ax = plt.axes()

ax.hist(samples, bins=range(3), density=False, color='0.7', edgecolor='k')

xticks = np.arange(2)+0.5
ax.set_xticks(xticks)
ax.set_xticklabels(['0', '1'])

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2042.png)

### 멀티누이 분포

```python
K = 6
mu = [1/21, 2/21, 3/21, 4/21, 5/21, 6/21]

# 확률변수 정의
cat_rv = multinomial(n=1, p=mu)

# 원핫인코딩된 변수
X = np.zeros((6,6))
X[np.arange(K), np.arange(K)] = 1

# 확률질량함수
for x in X:
    print(f"P(X={x})={cat_rv.pmf(x):.6f}")

fig = plt.figure(figsize=(6,5))
ax = plt.axes()

xticks = np.arange(6)

ax.bar(xticks+1, cat_rv.pmf(X), color='0.7', edgecolor='k')
ax.set_xticks(xticks+1)
ax.set_xlabel(r"$X$")
ax.set_ylabel("Probability")
ax.set_title(r"Multinoulli Distribution for $\mu$=[1/21, 2/21, 3/21, 4/21, 5/21, 6/21]")

ax.tick_params(axis='x', labelsize="small")
ax.tick_params(axis='y', labelsize="small")

# axes의 right, top 축 감추기
ax.spines["right"].set_visible(False)
ax.spines["top"].set_visible(False)

plt.show()
```

P(X=[1. 0. 0. 0. 0. 0.])=0.047619
P(X=[0. 1. 0. 0. 0. 0.])=0.095238
P(X=[0. 0. 1. 0. 0. 0.])=0.142857
P(X=[0. 0. 0. 1. 0. 0.])=0.190476
P(X=[0. 0. 0. 0. 1. 0.])=0.238095
P(X=[0. 0. 0. 0. 0. 1.])=0.285714

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2043.png)

### 멀티누이 분포 시뮬레이션

```python
# 시뮬레이션

# 랜덤 샘플링 (1000, 6)
samples = cat_rv.rvs(size=1000).argmax(axis=1)

fig = plt.figure(figsize=(6,5))
ax = plt.axes()

ax.hist(samples, bins=range(K+1), density=False, color='0.7', edgecolor='k')

xticks = np.arange(K+1)+0.5
ax.set_xticks(xticks)
ax.set_xticklabels(np.arange(K+1)+1)

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2044.png)

### 결합확률분포

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2045.png)

- 확률변수 X, Y가 결합된 확률 변수를 XY라고 하면
- 위 그림처럼 분포하는 결합 확률분포에 대해서 결합확률질량함수를 아래처럼 코딩

```python
def f_XY(x, y):
    if x in [5,6,7] and y in [8,9]:
        p = 0.0

        if (x,y) == (5,8):
            p = 0
        if (x,y) == (5,9):
            p = 0.3
        if (x,y) == (6,8):
            p = 0.4
        if (x,y) == (6,9):
            p = 0
        if (x,y) == (7,8):
            p = 0.1
        if (x,y) == (7,9):
            p = 0.2

        return p
    else:
        return 0
```

- 확률변수 X와 Y가 가질 수 있는 값들을 정의

```python
x_supp = np.array([5,6,7])
y_supp = np.array([8,9])
```

### 분포로부터 기댓값, 분산, 공분산

- X, Y의 가능한 값과 그 값에 대한 확률을 모두 알고 있으므로 이론적으로 기댓값, 분산, 공분산을 구할 수 있음

```python
# X, Y에 대한 기댓값을 각각 구함
mean_X = 0.0
for x in x_supp:
    for y in y_supp:
        mean_X += np.array([x])*f_XY(x, y)
print("E[X]=",mean_X)

mean_Y = 0.0
for x in x_supp:
    for y in y_supp:
        mean_Y += np.array([y])*f_XY(x, y)
print("E[Y]=",mean_Y)
```

```python
# 변수 XY에 대한 기댓값을 바로 구함

mean_XY = np.array([0., 0.])
for x in x_supp:
    for y in y_supp:
        mean_XY += np.array([x, y])*f_XY(x, y)
print("E[XY]=",mean_XY)
```

- 비슷하게 각 변수의 분산과 공분산을 이론적으로 구함

```python
var_X = 0.0
for x in x_supp:
    for y in y_supp:
        var_X += (np.array([x]) - mean_X)**2 * f_XY(x, y)
print("Var[X]=",var_X)

var_Y = 0.0
for x in x_supp:
    for y in y_supp:
        var_Y += (np.array([y]) - mean_Y)**2 * f_XY(x, y)
print("Var[Y]=",var_Y)
```

```python
cov_XY = 0.0
for x in x_supp:
    for y in y_supp:
        cov_XY += np.prod(np.array([x, y]) - mean_XY) * f_XY(x, y)
print("Cov[X,Y]=",cov_XY)
```

### 샘플로 부터 기댓값, 분산, 공분산

- 위 이론적으로 구한값과 분포로부터 샘플링한 샘플을 이용해서 구한 값들이 일치하는지 확인
- 아래 함수 `draw()`는 샘플링 함수

```python
def draw(XY, n):
    x_supp, y_supp, f_XY = XY
    
    #됨(x, y)인 샘플과 그에 대한 확률값을 리스트로 만든다.
    # [ ((x,y), f_XY), ..., ((x,y), f_XY) ]
    dist = [(sample, f_XY(*sample)) 
                for sample in itertools.product(x_supp, y_supp)]

    # 첫인자로 샘플의 개수, p에 샘플링 확률을 넘김
    # 그럼 0~샘플수-1 에 해당하는 숫자를 p에 맞게끔 샘플링
    # 그럼 이 숫자들은 dist[]에 순차적으로 저장되어있는 샘플의 인덱스가 됨 
    samples_i = np.random.choice(len(dist), size=n, p=[x[1] for x in dist])
    samples = np.array([dist[x][0] for x in samples_i])
    
    return samples
```

```python

# 10000개 샘플링
samples = draw((x_supp, y_supp, f_XY), 10000)
```

```python
# 샘플된 각 샘플들의 개수가 분포와 비슷한지 확인
np.unique(samples, axis=0, return_counts=True)
```

```python
# 샘플들의 평균
print("m=")
np.mean(samples, axis=0)
```

```python
# 샘플들의 분산, 공분산
print("s=")
np.cov(samples.T)
```

- 10000개 샘플중에 유일한 값은 네개밖에 없기 때문에 아래 그림에서 검은점으로 나타내었음
- 검은점과 평균값의 차이를 각 변으로 하는 사각형의 넓이를 그림으로 나타냄
- 공분산은 그림에 나타는 면적에 $f*_{XY}(x, y)$값을 곱해서 다 더한 것이므로 그림의 면적에 높이값으로 $f_*{XY}(x, y)$값을 곱한 부피의 합

```python
samples_uniq = np.unique(samples, axis=0)
deviations_uniq = np.unique(samples, axis=0) - mean_XY

fig = plt.figure(dpi=150)
ax = plt.axes()

covs = [ Rectangle( (mean_X, mean_Y), x[0], x[1], edgecolor='k', 
                   facecolor=colors[((x[0]*x[1]) > 0).astype(int)], alpha=0.3) 
            for x in deviations_uniq ]

for cov in covs:
    ax.add_patch(cov)

ax.plot(samples_uniq[:,0], samples_uniq[:,1], 'o', color='k')
ax.axhline(y=mean_Y, color='k')
ax.axvline(x=mean_X, color='k')
ax.plot(mean_X, mean_Y, 'o', color='r')
ax.text(mean_X+0.03, mean_Y+0.03, 'mean')
ax.text(5+0.03, 9-0.06, '(5-6)*(9-8.5)*f_XY(5,9)<0')
ax.text(7-0.85, 9-0.06, '(7-6)*(9-8.5)*f_XY(7,9)>0')
ax.text(6-0.85, 8+0.03, '(6-6)*(8-8.5)*f_XY(6,8)=0')
ax.text(7-0.85, 8+0.03, '(7-6)*(8-8.5)*f_XY(7,8)<0')

plt.show()
```

![Untitled](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/Untitled%2046.png)

## *중요* 베르누이 분포 추정

- 어떻게 분포랑 우리가 하려는 인공지능이랑 뉴럴 네트워크랑 연관되어있는가!

![스크린샷 2022-04-13 오후 2.44.35.png](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-04-13_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_2.44.35.png)

![스크린샷 2022-04-13 오후 2.46.30.png](6%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8C%20890ba/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2022-04-13_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_2.46.30.png)